{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1plt6eHti2Yu9scKvJnW32tUGNFG9o9gj","authorship_tag":"ABX9TyNrQyJwTjOh9C/QS/Yy2qEr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"up95mEMOqokg","executionInfo":{"status":"ok","timestamp":1714239724086,"user_tz":-300,"elapsed":42,"user":{"displayName":"Muhammad Shah","userId":"17841520657854613710"}},"outputId":"942c123a-ab5c-4a27-a698-8a162e3e964c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Folder/GenerativeAI/Readme-Generator-App-LLama3\n"]}],"source":["%cd /content/drive/MyDrive/Colab Folder/GenerativeAI/Readme-Generator-App-LLama3"]},{"cell_type":"code","source":["!pip install langchain_core"],"metadata":{"id":"Vmg_AkrK7i_t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%file requirements.txt\n","python-dotenv\n","streamlit\n","langchain_core\n","langchain_groq"],"metadata":{"id":"Ms8XcOgW7emF","executionInfo":{"status":"ok","timestamp":1714239731813,"user_tz":-300,"elapsed":9,"user":{"displayName":"Muhammad Shah","userId":"17841520657854613710"}},"outputId":"1e11c932-9a47-4013-d9f4-9122c7bed566","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing requirements.txt\n"]}]},{"cell_type":"code","source":["# setting environment variables\n","GROQ_API = 'GROQ_API='\n","with open('.env', 'a') as f:\n","    f.write(GROQ_API)"],"metadata":{"id":"U2YWdSEDrLji"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from dotenv import find_dotenv, load_dotenv"],"metadata":{"id":"DYpYR1KF6zIc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dotenv_path = '.env'\n","load_dotenv(dotenv_path)\n","GROQ_API = os.getenv('GROQ_API')"],"metadata":{"id":"ppVIXTCA8PqY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = \"print('hello word')\""],"metadata":{"id":"qwyTOF1HGL5i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_groq import ChatGroq\n","from langchain_core.prompts import ChatPromptTemplate\n","chat = ChatGroq(temperature=0.5,\n","                model_name=\"Llama3-70b-8192\",\n","                api_key=GROQ_API,\n","                max_tokens=100,\n","                model_kwargs={\n","                    \"top_p\": 1,\n","                    \"frequency_penalty\": 0.0,\n","                    \"presence_penalty\" : 0.0\n","                }\n","                )"],"metadata":{"id":"KNZ8nNpcGU8Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DEMO\n","system = \"You help developers creationg readme file from code as an Assistant don't include irrelevant words just give me readme text so that I can copy pate\"\n","human = '{query}'\n","prompt = ChatPromptTemplate.from_messages(messages=[('system', system), ('human', human)])\n","chain = prompt | chat\n","response = chain.invoke({\"query\": f'{text}'})"],"metadata":{"id":"eQ3C3-Om8PkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = \"print('hello word')\"\n","result = response.content\n","\n","print(text, end='\\n\\n')\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hPP0Q2vUGZn8","executionInfo":{"status":"ok","timestamp":1714164560087,"user_tz":-300,"elapsed":378,"user":{"displayName":"Muhammad Shah","userId":"17841520657854613710"}},"outputId":"dd522f9d-fd49-4c01-8615-43b5580b0ea9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["print('hello word')\n","\n","Hello World\n","============\n","\n","This is a simple Python program that prints \"hello world\" to the console.\n","\n","Usage\n","-----\n","\n","* Save this code to a file with a `.py` extension (e.g., `hello.py`).\n","* Run the file using Python (e.g., `python hello.py`).\n","\n","Output\n","------\n","\n","```\n","hello world\n","```\n"]}]},{"cell_type":"markdown","source":["Hello World\n","============\n","\n","This is a simple Python program that prints \"hello world\" to the console.\n","\n","Usage\n","-----\n","\n","* Save this code to a file with a `.py` extension (e.g., `hello.py`).\n","* Run the file using Python (e.g., `python hello.py`).\n","\n","Output\n","------\n","\n","```\n","hello world\n","```"],"metadata":{"id":"XpyNiYRkJwXg"}},{"cell_type":"code","source":["%%file readme_generator.py\n","from langchain_groq import ChatGroq\n","from langchain_core.prompts import ChatPromptTemplate\n","chat = ChatGroq(temperature=0.5,\n","                model_name=\"Llama3-70b-8192\",\n","                api_key=GROQ_API,\n","                max_tokens=100,\n","                model_kwargs={\n","                    \"top_p\": 1,\n","                    \"frequency_penalty\": 0.0,\n","                    \"presence_penalty\" : 0.0\n","                }\n","                )\n","def ask(text):\n","    system = \"You help developers creationg readme file from code as an Assistant don't include irrelevant words just give me readme text so that I can copy pate\"\n","    human = '{query} \\n\\n `Read the code and generate README.md file?`'\n","    prompt = ChatPromptTemplate.from_messages(messages=[('system', system), ('human', human)])\n","    chain = prompt | chat\n","    response = chain.invoke({\"query\": f'{text}'}).content\n","    return response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKE0mmnFKIba","executionInfo":{"status":"ok","timestamp":1714166721872,"user_tz":-300,"elapsed":442,"user":{"displayName":"Muhammad Shah","userId":"17841520657854613710"}},"outputId":"2a4149a5-dff5-4bd0-e171-68c81322e0e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing readme_generator.py\n"]}]},{"cell_type":"code","source":["%%file app.py\n","import streamlit as st\n","import readme_generator as rmgen\n","\n","st.header('README Generation with the help of Llama3-70b from code')\n","uploaded_file = st.file_uploader('Upload Code File')\n","\n","if uploaded_file is not None:\n","    content = uploaded_file.read.decode()\n","    response = rmgen.ask(content)\n","    st.markdown(\"\"\"-----------------------------\"\"\")\n","    st.subheader('Response')\n","    st.text(response)\n","    st.markdown(\"\"\"-----------------------------\"\"\")\n","    st.subheader('Preview')\n","    st.markdown(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yaf90W4pNdh_","executionInfo":{"status":"ok","timestamp":1714166122307,"user_tz":-300,"elapsed":564,"user":{"displayName":"Muhammad Shah","userId":"17841520657854613710"}},"outputId":"5b4180d5-1d1f-4555-86f6-c94683c6e364"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ASDipmbEQq8y"},"execution_count":null,"outputs":[]}]}